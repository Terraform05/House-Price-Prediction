{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from helper import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = pd.read_csv('../new_data/clean_train_numeric.csv')\n",
    "numeric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categoric_df = pd.read_csv('../new_data/clean_train_categoric.csv')\n",
    "categoric_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(numeric_df, categoric_df, on='Id', how='inner')\n",
    "merged_df.to_csv('../new_data/clean_train_merged.csv', index=False)\n",
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_nulls(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split df into a few smaller ones, each with sale price as first column\n",
    "#keep top 16 features with correlation to sale price\n",
    "\n",
    "sale_price_correlations = merged_df.corr()['SalePrice'].sort_values(ascending=False)[0:30]\n",
    "sale_price_correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_corr_df = merged_df[sale_price_correlations.index.to_list()]\n",
    "high_corr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ajr_plot_correlations(high_corr_df, 'SalePrice')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, root_mean_squared_error\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor, BaggingRegressor, ExtraTreesRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "X = merged_df.drop('SalePrice', axis=1)\n",
    "y = merged_df['SalePrice']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "pca = PCA(n_components=30)\n",
    "\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "explained_variance = np.cumsum(pca.explained_variance_ratio_)\n",
    "print(f\"Total explained variance with selected components: {explained_variance[-1]:.4f}\")\n",
    "print(f\"Number of components selected: {pca.n_components_}\")\n",
    "\n",
    "param_grids = {\n",
    "    'Ridge': {'alpha': [0.1, 1, 10, 100]},\n",
    "    'Lasso': {'alpha': [0.01, 0.1, 1, 10]},\n",
    "    'ElasticNet': {'alpha': [0.01, 0.1, 1, 10], 'l1_ratio': [0.2, 0.5, 0.8]},\n",
    "    'RandomForestRegressor': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'GradientBoostingRegressor': {'learning_rate': [0.01, 0.1, 0.2], 'n_estimators': [100, 200]},\n",
    "    'AdaBoostRegressor': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1, 1]},\n",
    "    'BaggingRegressor': {'n_estimators': [10, 50, 100]},\n",
    "    'ExtraTreesRegressor': {'n_estimators': [100, 200], 'max_depth': [None, 10, 20]},\n",
    "    'DecisionTreeRegressor': {'max_depth': [None, 10, 20]},\n",
    "    'KNeighborsRegressor': {'n_neighbors': [3, 5, 10]},\n",
    "    'SVR': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']},\n",
    "}\n",
    "\n",
    "models = {\n",
    "    'Ridge': Ridge(),\n",
    "    'Lasso': Lasso(),\n",
    "    'ElasticNet': ElasticNet(),\n",
    "    'RandomForestRegressor': RandomForestRegressor(),\n",
    "    'GradientBoostingRegressor': GradientBoostingRegressor(),\n",
    "    'AdaBoostRegressor': AdaBoostRegressor(),\n",
    "    'BaggingRegressor': BaggingRegressor(),\n",
    "    'ExtraTreesRegressor': ExtraTreesRegressor(),\n",
    "    'DecisionTreeRegressor': DecisionTreeRegressor(),\n",
    "    'KNeighborsRegressor': KNeighborsRegressor(),\n",
    "    'SVR': SVR(),\n",
    "}\n",
    "\n",
    "results_pca = {}\n",
    "best_models_pca = {}\n",
    "\n",
    "print('Training models with PCA-transformed features...')\n",
    "for name, model in tqdm(models.items()):\n",
    "    grid_search = GridSearchCV(model, param_grids.get(name, {}), cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "    grid_search.fit(X_train_pca, y_train)\n",
    "\n",
    "    best_model = grid_search.best_estimator_\n",
    "    best_rmse = np.sqrt(-grid_search.best_score_) # RMSE\n",
    "\n",
    "    results_pca[name] = best_rmse\n",
    "    best_models_pca[name] = best_model\n",
    "\n",
    "print('\\nModel Performance with PCA (RMSE):')\n",
    "for name, rmse in results_pca.items():\n",
    "    print(f'{name}: {rmse:.4f}')\n",
    "\n",
    "print('\\nBest Model with PCA:')\n",
    "best_model_pca = best_models_pca[min(results_pca, key=results_pca.get)]\n",
    "print(f'{best_model_pca}: {results_pca[min(results_pca, key=results_pca.get)]:.4f}')\n",
    "\n",
    "print(best_model_pca.get_params())\n",
    "\n",
    "# Visualize explained variance\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(explained_variance, marker='o', label=\"Cumulative Explained Variance\")\n",
    "plt.axhline(y=explained_variance[-1], color='r', linestyle='--',label=f\"{explained_variance[-1]:.2f} variance explained\")\n",
    "plt.xlabel(\"Number of Components\")\n",
    "plt.ylabel(\"Cumulative Explained Variance\")\n",
    "plt.title(\"Explained Variance by PCA Components\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "#MSE\n",
    "y_pred = best_model_pca.predict(X_test_pca)\n",
    "rmse = root_mean_squared_error(y_test, y_pred)\n",
    "print('\\n')\n",
    "print(f'MSE: {rmse}')\n",
    "\n",
    "r2_score = best_model_pca.score(X_test_pca, y_test)\n",
    "print(f'R2 Score: {r2_score}')\n",
    "\n",
    "#plot predictions vs actual\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([0, np.max(y_test)], [0, np.max(y_test)], 'r--')\n",
    "plt.xlabel('Actual')\n",
    "plt.ylabel('Predicted')\n",
    "plt.title('Predicted vs Actual')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
